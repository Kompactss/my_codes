{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "baseline-code-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bac0dc8ef9954d47aafd2d4304a66534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41f9ea9929154cb09bbbde0fbc6aaab2",
              "IPY_MODEL_246e9685de974a45b23b8257ef49c633",
              "IPY_MODEL_f481c9907cf4425da23271519614ffed"
            ],
            "layout": "IPY_MODEL_9615f5c6705d48a7a2e85741013b4a45"
          }
        },
        "41f9ea9929154cb09bbbde0fbc6aaab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299e6f3633494874ae6c154402285e38",
            "placeholder": "​",
            "style": "IPY_MODEL_ff238c7fbbe94fdc80550f6f6e36b06e",
            "value": "Downloading: 100%"
          }
        },
        "246e9685de974a45b23b8257ef49c633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12944608793240d4ad5b844bf562b7a2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_415924617c944566bb65343e0e7a8891",
            "value": 231508
          }
        },
        "f481c9907cf4425da23271519614ffed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b33385a2054f319e8c6e4906dc212a",
            "placeholder": "​",
            "style": "IPY_MODEL_643a39d8c76a416ca1b7b861b9bf53bf",
            "value": " 226k/226k [00:00&lt;00:00, 625kB/s]"
          }
        },
        "9615f5c6705d48a7a2e85741013b4a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299e6f3633494874ae6c154402285e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff238c7fbbe94fdc80550f6f6e36b06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12944608793240d4ad5b844bf562b7a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415924617c944566bb65343e0e7a8891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b33385a2054f319e8c6e4906dc212a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643a39d8c76a416ca1b7b861b9bf53bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1916be6a035e4b18a6af8189578319ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95f8e270e74942598ff8226137d65acc",
              "IPY_MODEL_26abade608f14c07a391bb2c68156c10",
              "IPY_MODEL_11b87859dd8d40dfa43554b6fc68ae2e"
            ],
            "layout": "IPY_MODEL_bd89feeeb92249558a0a718e3adf1a51"
          }
        },
        "95f8e270e74942598ff8226137d65acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0dbfcea7fb44efb84fc4c4cd2bc6129",
            "placeholder": "​",
            "style": "IPY_MODEL_2af00c9160234dd2922f3adfc250f172",
            "value": "Downloading: 100%"
          }
        },
        "26abade608f14c07a391bb2c68156c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6196e8c6234f9b9bd39353493a64e7",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e897dec1158b4e8490dcbefd52a037c6",
            "value": 28
          }
        },
        "11b87859dd8d40dfa43554b6fc68ae2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94eaa98417a24488bcdbae18f7776979",
            "placeholder": "​",
            "style": "IPY_MODEL_f240bb50b27b4f20911483ebe4c80e70",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.09kB/s]"
          }
        },
        "bd89feeeb92249558a0a718e3adf1a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dbfcea7fb44efb84fc4c4cd2bc6129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2af00c9160234dd2922f3adfc250f172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad6196e8c6234f9b9bd39353493a64e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e897dec1158b4e8490dcbefd52a037c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94eaa98417a24488bcdbae18f7776979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f240bb50b27b4f20911483ebe4c80e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a272e0c856d4a4db21eff8443aaae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b74addb7ab884a6092d3c07a7a00482a",
              "IPY_MODEL_ba2059ba3ab4461b9a45c18124eae5e0",
              "IPY_MODEL_e21d66ec95ba423a93bbe5cd6d5abbdd"
            ],
            "layout": "IPY_MODEL_39d1db6ec0d84b3388fedb5def174a1c"
          }
        },
        "b74addb7ab884a6092d3c07a7a00482a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1684816986b4bbe9450749d78781624",
            "placeholder": "​",
            "style": "IPY_MODEL_a7708a0c7864430faa9d2526905e4ac4",
            "value": "Downloading: 100%"
          }
        },
        "ba2059ba3ab4461b9a45c18124eae5e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8f4f01323d4fedada386b98711e915",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16b81d78bf0d4737ba086dc0af628806",
            "value": 570
          }
        },
        "e21d66ec95ba423a93bbe5cd6d5abbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c03beb93ec144559b2c4f231d56829ce",
            "placeholder": "​",
            "style": "IPY_MODEL_7a5d57e3ef1845e4b988a84e3dfbf258",
            "value": " 570/570 [00:00&lt;00:00, 19.8kB/s]"
          }
        },
        "39d1db6ec0d84b3388fedb5def174a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1684816986b4bbe9450749d78781624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7708a0c7864430faa9d2526905e4ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a8f4f01323d4fedada386b98711e915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b81d78bf0d4737ba086dc0af628806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c03beb93ec144559b2c4f231d56829ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5d57e3ef1845e4b988a84e3dfbf258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kompactss/my_codes/blob/main/baseline_code_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import requirements"
      ],
      "metadata": {
        "id": "TH32rzgprvgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "G9EvC1HBuf41",
        "outputId": "3c9d239e-5e52-48b6-c183-cd3788153f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 77.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 62.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW\n",
        ")"
      ],
      "metadata": {
        "id": "AAdLxrUZrvgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preprocess"
      ],
      "metadata": {
        "id": "ASWOOmXqrvgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join(file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ],
      "metadata": {
        "id": "RAnU6w29rvgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "Ui2HOCflrvgR",
        "outputId": "2d8a0c0b-be70-47fc-8bd4-2a50f8ecd95f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bac0dc8ef9954d47aafd2d4304a66534",
            "41f9ea9929154cb09bbbde0fbc6aaab2",
            "246e9685de974a45b23b8257ef49c633",
            "f481c9907cf4425da23271519614ffed",
            "9615f5c6705d48a7a2e85741013b4a45",
            "299e6f3633494874ae6c154402285e38",
            "ff238c7fbbe94fdc80550f6f6e36b06e",
            "12944608793240d4ad5b844bf562b7a2",
            "415924617c944566bb65343e0e7a8891",
            "c2b33385a2054f319e8c6e4906dc212a",
            "643a39d8c76a416ca1b7b861b9bf53bf",
            "1916be6a035e4b18a6af8189578319ba",
            "95f8e270e74942598ff8226137d65acc",
            "26abade608f14c07a391bb2c68156c10",
            "11b87859dd8d40dfa43554b6fc68ae2e",
            "bd89feeeb92249558a0a718e3adf1a51",
            "c0dbfcea7fb44efb84fc4c4cd2bc6129",
            "2af00c9160234dd2922f3adfc250f172",
            "ad6196e8c6234f9b9bd39353493a64e7",
            "e897dec1158b4e8490dcbefd52a037c6",
            "94eaa98417a24488bcdbae18f7776979",
            "f240bb50b27b4f20911483ebe4c80e70",
            "2a272e0c856d4a4db21eff8443aaae50",
            "b74addb7ab884a6092d3c07a7a00482a",
            "ba2059ba3ab4461b9a45c18124eae5e0",
            "e21d66ec95ba423a93bbe5cd6d5abbdd",
            "39d1db6ec0d84b3388fedb5def174a1c",
            "a1684816986b4bbe9450749d78781624",
            "a7708a0c7864430faa9d2526905e4ac4",
            "3a8f4f01323d4fedada386b98711e915",
            "16b81d78bf0d4737ba086dc0af628806",
            "c03beb93ec144559b2c4f231d56829ce",
            "7a5d57e3ef1845e4b988a84e3dfbf258"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bac0dc8ef9954d47aafd2d4304a66534"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1916be6a035e4b18a6af8189578319ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a272e0c856d4a4db21eff8443aaae50"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "4jVuK-V1uq3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ttzRlY4Ov0jZ",
        "outputId": "2e1af0ac-dc42-45f0-f0c6-8ea20e0b9856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\t sentiment.dev.1    sentiment.train.1\n",
            "sentiment.dev.0  sentiment.train.0  test_no_label.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ],
      "metadata": {
        "id": "BAgztXIBrvgS",
        "outputId": "0f252d9f-445d-4f59-aaf2-f83b9be5e1e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos[:10]"
      ],
      "metadata": {
        "id": "wRh2WjGRrvgS",
        "outputId": "d49714cb-af39-440a-a7c0-f604f03acd41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 6581 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3347 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ],
      "metadata": {
        "id": "JdpQQQMUrvgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ],
      "metadata": {
        "id": "wCz5ey8xrvgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "UuvkMczvrvgU",
        "outputId": "b03d36b3-d208-4d5e-df35-dfd34a0b4429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n",
            "(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n",
            "       19247,  1012,   102]), array([1]))\n",
            "(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n",
            "        5404,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n",
            "(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_style(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ],
      "metadata": {
        "id": "B0wRUBYSrvgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size=32\n",
        "eval_batch_size=64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_style,\n",
        "                                           pin_memory=True, num_workers=2)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_style,\n",
        "                                         num_workers=2)"
      ],
      "metadata": {
        "id": "5saagig0rvgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "random_seed=42\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zvFqCaCnrvgW",
        "outputId": "2950de37-75f0-47b3-c7e3-7c31f20cb1e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "learning_rate = 5e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "dWwhmyMyrvgW",
        "outputId": "35ffc315-9930-450b-c692-326c9ea1fa9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ],
      "metadata": {
        "id": "MztU-L83rvgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_epoch = 3\n",
        "lowest_valid_loss = 9999.\n",
        "for epoch in range(train_epoch):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch+1}\") # epoch 수가 헷갈려서 1 더함\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids,\n",
        "                                       position_ids=position_ids,\n",
        "                                       labels=labels)\n",
        "\n",
        "                        logits = output.logits\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "                model.train()  # model.eval()로 검증을 마친 후 학습모드로 다시 돌아가지 않음    \n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    print('Acc for model which have lower valid loss: ', acc)\n",
        "                    torch.save(model.state_dict(), \"./pytorch_model.bin\")"
      ],
      "metadata": {
        "id": "DuZfvzpGrvgW",
        "outputId": "e4098831-da1d-4c00-efd4-3cb4082e71f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  20%|█▉        | 2769/13852 [02:59<11:59, 15.41batch/s, loss=0.0271]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.19it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.37it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.02it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.06it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 32.54it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 33.47it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.13it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.00it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 34.79it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 33.89it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.18it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 32.85it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.55it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 32.87it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.65it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.03it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.96825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|███▉      | 5539/13852 [06:01<08:54, 15.56batch/s, loss=0.0573]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.55it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.15it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.15it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.30it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.07it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.23it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.47it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.37it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.35it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.40it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.69it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.25it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.98it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.14it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.81it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.18it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  60%|█████▉    | 8309/13852 [09:02<05:55, 15.60batch/s, loss=0.113] \n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.75it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.65it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 29.19it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 32.13it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.58it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.74it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.94it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.58it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.65it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.69it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.70it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.15it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.94it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.15it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.16it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.36it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|███████▉  | 11079/13852 [12:02<02:54, 15.85batch/s, loss=0.0294]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.39it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.99it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.82it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 32.04it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.54it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.89it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.35it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 36.08it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.91it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.62it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.81it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.30it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.98it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.33it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.12it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.62it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|█████████▉| 13849/13852 [15:01<00:00, 15.39batch/s, loss=0.0102]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:07,  7.80it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.34it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.46it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.67it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.42it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.61it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.02it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.75it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.51it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.30it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.56it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.08it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.80it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.02it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.95it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.50it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 13852/13852 [15:05<00:00, 15.30batch/s, loss=0.00373]\n",
            "Epoch 2:  20%|█▉        | 2769/13852 [02:58<11:49, 15.63batch/s, loss=0.00569]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.33it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.24it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 29.10it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 32.38it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.81it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.92it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.24it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 36.01it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.60it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.41it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.50it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.09it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.78it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 32.95it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.89it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.21it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  40%|███▉      | 5539/13852 [05:58<08:41, 15.95batch/s, loss=0.00205]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.20it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.88it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.50it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.74it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.32it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.78it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.24it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.86it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.84it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.71it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.89it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.29it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 33.18it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.32it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.98it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.26it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  60%|█████▉    | 8309/13852 [08:58<05:52, 15.70batch/s, loss=0.0354]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.38it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.13it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.81it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.83it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.45it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.75it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.02it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.94it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.54it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.45it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.61it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.08it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.70it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 32.99it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.79it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.16it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|███████▉  | 11079/13852 [11:58<02:56, 15.74batch/s, loss=0.0802]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.52it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.64it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.58it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.70it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.28it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.66it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.65it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.54it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.47it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.48it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.65it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.21it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.64it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 32.86it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.73it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.12it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|█████████▉| 13849/13852 [14:56<00:00, 16.06batch/s, loss=0.177] \n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.72it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.29it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 29.09it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 32.39it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.91it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 35.17it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.45it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.83it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.60it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.65it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.92it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.47it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 33.10it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.34it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.28it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.68it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 13852/13852 [14:59<00:00, 15.41batch/s, loss=0.00414]\n",
            "Epoch 3:  20%|█▉        | 2769/13852 [02:55<11:48, 15.64batch/s, loss=0.052]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.46it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.93it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.88it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 32.14it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.80it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.79it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 35.34it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 36.10it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.79it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.79it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.85it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.19it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.91it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.23it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.04it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.46it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  40%|███▉      | 5539/13852 [05:53<08:45, 15.82batch/s, loss=0.0196] \n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.43it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 23.50it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.79it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.90it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.59it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.68it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.89it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.87it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.83it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.63it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.80it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.45it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.98it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.31it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.11it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.53it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  60%|█████▉    | 8309/13852 [08:52<05:53, 15.68batch/s, loss=0.00681]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.41it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.79it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.07it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.36it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.09it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.62it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.90it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.55it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.48it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.43it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.67it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.26it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.99it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.18it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 33.07it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.36it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  80%|███████▉  | 11079/13852 [11:53<02:58, 15.50batch/s, loss=0.0488] \n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.38it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.91it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.28it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.38it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.01it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.03it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.20it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.12it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.18it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.29it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.60it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.07it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.77it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 33.03it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.90it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.31it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|█████████▉| 13849/13852 [14:54<00:00, 15.49batch/s, loss=0.00288]\n",
            "Eval:   0%|          | 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   2%|▏         | 1/63 [00:00<00:08,  7.31it/s]\u001b[A\n",
            "Eval:   8%|▊         | 5/63 [00:00<00:02, 22.94it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 9/63 [00:00<00:01, 28.33it/s]\u001b[A\n",
            "Eval:  21%|██        | 13/63 [00:00<00:01, 31.52it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 17/63 [00:00<00:01, 33.33it/s]\u001b[A\n",
            "Eval:  33%|███▎      | 21/63 [00:00<00:01, 34.60it/s]\u001b[A\n",
            "Eval:  40%|███▉      | 25/63 [00:00<00:01, 34.93it/s]\u001b[A\n",
            "Eval:  46%|████▌     | 29/63 [00:00<00:00, 35.69it/s]\u001b[A\n",
            "Eval:  52%|█████▏    | 33/63 [00:01<00:00, 35.63it/s]\u001b[A\n",
            "Eval:  59%|█████▊    | 37/63 [00:01<00:00, 34.48it/s]\u001b[A\n",
            "Eval:  65%|██████▌   | 41/63 [00:01<00:00, 33.60it/s]\u001b[A\n",
            "Eval:  71%|███████▏  | 45/63 [00:01<00:00, 33.08it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 49/63 [00:01<00:00, 32.76it/s]\u001b[A\n",
            "Eval:  84%|████████▍ | 53/63 [00:01<00:00, 32.97it/s]\u001b[A\n",
            "Eval:  90%|█████████ | 57/63 [00:01<00:00, 32.71it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 61/63 [00:01<00:00, 33.30it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 13852/13852 [14:57<00:00, 15.43batch/s, loss=0.0634]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('test_no_label.csv')"
      ],
      "metadata": {
        "id": "P95gtlnurvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_df['Id']"
      ],
      "metadata": {
        "id": "cLDzC10ErvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ],
      "metadata": {
        "id": "jnt693N0rvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ],
      "metadata": {
        "id": "7C5PpXtlrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[:10]"
      ],
      "metadata": {
        "id": "1aqse7SHrvgY",
        "outputId": "bcb41bc6-3251-4c4e-d906-f0641a7a2f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 2009 1005 1055 1037 2878 2047 3325 1998 2047 26389 2169 2051 2017 2175 1012 102',\n",
              " '101 2061 15640 2013 2019 2214 5440 1012 102',\n",
              " '101 2009 2003 1996 2087 14469 7273 1999 1996 3028 1012 102',\n",
              " '101 2079 2025 3696 1037 10084 2007 2122 2111 1012 102',\n",
              " '101 1045 2001 6091 1998 2016 2081 2033 2514 2061 6625 1998 6160 1012 102',\n",
              " '101 1996 2069 2518 2057 2363 2008 2001 2980 2001 1996 4157 1012 102',\n",
              " '101 2053 1010 2025 1996 3924 2012 2004 2226 1010 1996 3924 1999 3502 2152 1012 102',\n",
              " '101 2027 3288 2009 2041 2392 2005 2017 1998 2024 2200 14044 1012 102',\n",
              " '101 4606 1996 12043 2106 1050 1005 1056 2130 2113 2129 2000 2147 1996 3274 1012 102',\n",
              " '101 2027 2031 2019 6581 4989 1997 25025 2015 2000 5454 2013 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ],
      "metadata": {
        "id": "cZi14gnnrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ],
      "metadata": {
        "id": "erHjGE9rrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_style_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ],
      "metadata": {
        "id": "-XGRJt9T5E6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_style_test,\n",
        "                                          num_workers=2)"
      ],
      "metadata": {
        "id": "gZ0l1HparvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ],
      "metadata": {
        "id": "XoSHTbJUrvgZ",
        "outputId": "b7e51228-3194-48c7-9404-6aa741f10f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Test:   3%|▎         | 1/32 [00:00<00:04,  7.37it/s]\u001b[A\n",
            "Test:  22%|██▏       | 7/32 [00:00<00:00, 32.13it/s]\u001b[A\n",
            "Test:  41%|████      | 13/32 [00:00<00:00, 41.68it/s]\u001b[A\n",
            "Test:  59%|█████▉    | 19/32 [00:00<00:00, 45.71it/s]\u001b[A\n",
            "Test:  78%|███████▊  | 25/32 [00:00<00:00, 48.89it/s]\u001b[A\n",
            "Test:  97%|█████████▋| 31/32 [00:00<00:00, 51.18it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Category'] = predictions"
      ],
      "metadata": {
        "id": "tGO3aS-VrvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Category']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcWY8jEse5y4",
        "outputId": "6c6ea83a-055f-4fec-8f5f-38acc8587e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "995    0\n",
              "996    0\n",
              "997    1\n",
              "998    0\n",
              "999    1\n",
              "Name: Category, Length: 1000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('submission(1).csv', index=False)"
      ],
      "metadata": {
        "id": "NtlqYC0ykksd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0nMhBYRe7rB6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}